{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found the config file in: ./.azureml/config.json\n"
     ]
    }
   ],
   "source": [
    "from azure.ai.ml import MLClient\n",
    "from azure.identity import DefaultAzureCredential\n",
    "\n",
    "ml_client = MLClient.from_config(credential=DefaultAzureCredential())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "\n",
    "# Keras settings\n",
    "batch_size = 32\n",
    "num_classes = 10\n",
    "epochs = 5\n",
    "num_predictions = 20\n",
    "\n",
    "# the data split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "# defining our model \n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# define model name and file locations\n",
    "model_name = 'keras_cifar10_trained_model.tf'\n",
    "model_output_dir = os.path.join(os.getcwd(), 'outputs')\n",
    "\n",
    "# initiate Adam optimizer (https://keras.io/api/optimizers/adam/)\n",
    "opt = Adam(learning_rate=0.001)\n",
    "\n",
    "# define checkpoint function to only save the model after each epoch if it is \"better\"\n",
    "# (decided based on the validation loss function) in the output file path\n",
    "if not os.path.isdir(model_output_dir):\n",
    "    os.makedirs(model_output_dir)\n",
    "model_path = os.path.join(model_output_dir, model_name)\n",
    "checkpoint_cb = ModelCheckpoint(model_path, monitor='val_loss', save_best_only=True)\n",
    "\n",
    "# define the loss function, optimizer and additionally tracked metrics of the model training\n",
    "# (https://keras.io/api/losses/probabilistic_losses/#categoricalcrossentropy-class)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "azureml://switzerlandnorth.api.azureml.ms/mlflow/v1.0/subscriptions/3a01bfbc-e48f-4e7d-9ea4-dcf5d7e90278/resourceGroups/ml-edu/providers/Microsoft.MachineLearningServices/workspaces/ml-edu\n"
     ]
    }
   ],
   "source": [
    "# Get the Azure Machine Learning Tracking URI\n",
    "mlflow_tracking_uri = ml_client.workspaces.get(ml_client.workspace_name).mlflow_tracking_uri\n",
    "print(mlflow_tracking_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='', creation_time=1690355118879, experiment_id='d1cf2d6c-b32f-437c-9d6e-6f0cc7882bc9', last_update_time=None, lifecycle_stage='active', name='cifar10_cnn_local', tags={}>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import mlflow\n",
    "\n",
    "# Configuring the tracking URI\n",
    "mlflow.set_tracking_uri(mlflow_tracking_uri)\n",
    "\n",
    "# Creating an MLflow experiment\n",
    "experiment_name = 'cifar10_cnn_local'\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/08/14 12:12:08 WARNING mlflow.tensorflow: Failed to log training dataset information to MLflow Tracking. Reason: API request to endpoint /api/2.0/mlflow/runs/log-inputs failed with error code 404 != 200. Response body: ''\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1250/1250 [==============================] - ETA: 0s - loss: 1.7273 - accuracy: 0.3692"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The following argument(s) are not supported with the native Keras format: ['options']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m mlflow\u001b[39m.\u001b[39mtensorflow\u001b[39m.\u001b[39mautolog()\n\u001b[1;32m      4\u001b[0m \u001b[39m# train the model for a certain number of epochs\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m model\u001b[39m.\u001b[39;49mfit(x_train, y_train,\n\u001b[1;32m      6\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m      7\u001b[0m         epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m      8\u001b[0m         validation_split\u001b[39m=\u001b[39;49m \u001b[39m0.2\u001b[39;49m,\n\u001b[1;32m      9\u001b[0m         shuffle\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     10\u001b[0m         callbacks\u001b[39m=\u001b[39;49m[checkpoint_cb])\n",
      "File \u001b[0;32m/opt/conda/envs/ml-env/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py:550\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    540\u001b[0m try_log_autologging_event(\n\u001b[1;32m    541\u001b[0m     AutologgingEventLogger\u001b[39m.\u001b[39mget_logger()\u001b[39m.\u001b[39mlog_patch_function_start,\n\u001b[1;32m    542\u001b[0m     session,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    546\u001b[0m     kwargs,\n\u001b[1;32m    547\u001b[0m )\n\u001b[1;32m    549\u001b[0m \u001b[39mif\u001b[39;00m patch_is_class:\n\u001b[0;32m--> 550\u001b[0m     patch_function\u001b[39m.\u001b[39;49mcall(call_original, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    551\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    552\u001b[0m     patch_function(call_original, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m/opt/conda/envs/ml-env/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py:168\u001b[0m, in \u001b[0;36mPatchFunction.call\u001b[0;34m(cls, original, *args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[1;32m    167\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcall\u001b[39m(\u001b[39mcls\u001b[39m, original, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m--> 168\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mcls\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__call__\u001b[39;49m(original, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/conda/envs/ml-env/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py:179\u001b[0m, in \u001b[0;36mPatchFunction.__call__\u001b[0;34m(self, original, *args, **kwargs)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_on_exception(e)\n\u001b[1;32m    176\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    177\u001b[0m     \u001b[39m# Regardless of what happens during the `_on_exception` callback, reraise\u001b[39;00m\n\u001b[1;32m    178\u001b[0m     \u001b[39m# the original implementation exception once the callback completes\u001b[39;00m\n\u001b[0;32m--> 179\u001b[0m     \u001b[39mraise\u001b[39;00m e\n",
      "File \u001b[0;32m/opt/conda/envs/ml-env/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py:172\u001b[0m, in \u001b[0;36mPatchFunction.__call__\u001b[0;34m(self, original, *args, **kwargs)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, original, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    171\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 172\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_patch_implementation(original, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    173\u001b[0m     \u001b[39mexcept\u001b[39;00m (\u001b[39mException\u001b[39;00m, \u001b[39mKeyboardInterrupt\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    174\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/envs/ml-env/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py:230\u001b[0m, in \u001b[0;36mwith_managed_run.<locals>.PatchWithManagedRun._patch_implementation\u001b[0;34m(self, original, *args, **kwargs)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m mlflow\u001b[39m.\u001b[39mactive_run():\n\u001b[1;32m    228\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmanaged_run \u001b[39m=\u001b[39m create_managed_run()\n\u001b[0;32m--> 230\u001b[0m result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m_patch_implementation(original, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    232\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmanaged_run:\n\u001b[1;32m    233\u001b[0m     mlflow\u001b[39m.\u001b[39mend_run(RunStatus\u001b[39m.\u001b[39mto_string(RunStatus\u001b[39m.\u001b[39mFINISHED))\n",
      "File \u001b[0;32m/opt/conda/envs/ml-env/lib/python3.10/site-packages/mlflow/tensorflow/__init__.py:1268\u001b[0m, in \u001b[0;36mautolog.<locals>.FitPatch._patch_implementation\u001b[0;34m(self, original, inst, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1261\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m   1262\u001b[0m         _logger\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m   1263\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mFailed to log training dataset information to \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1264\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mMLflow Tracking. Reason: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1265\u001b[0m             e,\n\u001b[1;32m   1266\u001b[0m         )\n\u001b[0;32m-> 1268\u001b[0m history \u001b[39m=\u001b[39m original(inst, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1270\u001b[0m \u001b[39mif\u001b[39;00m log_models:\n\u001b[1;32m   1271\u001b[0m     _log_keras_model(history, args)\n",
      "File \u001b[0;32m/opt/conda/envs/ml-env/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py:533\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original\u001b[0;34m(*og_args, **og_kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m         original_result \u001b[39m=\u001b[39m original(\u001b[39m*\u001b[39m_og_args, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39m_og_kwargs)\n\u001b[1;32m    531\u001b[0m         \u001b[39mreturn\u001b[39;00m original_result\n\u001b[0;32m--> 533\u001b[0m \u001b[39mreturn\u001b[39;00m call_original_fn_with_event_logging(_original_fn, og_args, og_kwargs)\n",
      "File \u001b[0;32m/opt/conda/envs/ml-env/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py:468\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original_fn_with_event_logging\u001b[0;34m(original_fn, og_args, og_kwargs)\u001b[0m\n\u001b[1;32m    459\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    460\u001b[0m     try_log_autologging_event(\n\u001b[1;32m    461\u001b[0m         AutologgingEventLogger\u001b[39m.\u001b[39mget_logger()\u001b[39m.\u001b[39mlog_original_function_start,\n\u001b[1;32m    462\u001b[0m         session,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    466\u001b[0m         og_kwargs,\n\u001b[1;32m    467\u001b[0m     )\n\u001b[0;32m--> 468\u001b[0m     original_fn_result \u001b[39m=\u001b[39m original_fn(\u001b[39m*\u001b[39;49mog_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mog_kwargs)\n\u001b[1;32m    470\u001b[0m     try_log_autologging_event(\n\u001b[1;32m    471\u001b[0m         AutologgingEventLogger\u001b[39m.\u001b[39mget_logger()\u001b[39m.\u001b[39mlog_original_function_success,\n\u001b[1;32m    472\u001b[0m         session,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    476\u001b[0m         og_kwargs,\n\u001b[1;32m    477\u001b[0m     )\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m original_fn_result\n",
      "File \u001b[0;32m/opt/conda/envs/ml-env/lib/python3.10/site-packages/mlflow/utils/autologging_utils/safety.py:530\u001b[0m, in \u001b[0;36msafe_patch.<locals>.safe_patch_function.<locals>.call_original.<locals>._original_fn\u001b[0;34m(*_og_args, **_og_kwargs)\u001b[0m\n\u001b[1;32m    522\u001b[0m \u001b[39m# Show all non-MLflow warnings as normal (i.e. not as event logs)\u001b[39;00m\n\u001b[1;32m    523\u001b[0m \u001b[39m# during original function execution, even if silent mode is enabled\u001b[39;00m\n\u001b[1;32m    524\u001b[0m \u001b[39m# (`silent=True`), since these warnings originate from the ML framework\u001b[39;00m\n\u001b[1;32m    525\u001b[0m \u001b[39m# or one of its dependencies and are likely relevant to the caller\u001b[39;00m\n\u001b[1;32m    526\u001b[0m \u001b[39mwith\u001b[39;00m set_non_mlflow_warnings_behavior_for_current_thread(\n\u001b[1;32m    527\u001b[0m     disable_warnings\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    528\u001b[0m     reroute_warnings\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m    529\u001b[0m ):\n\u001b[0;32m--> 530\u001b[0m     original_result \u001b[39m=\u001b[39m original(\u001b[39m*\u001b[39;49m_og_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m_og_kwargs)\n\u001b[1;32m    531\u001b[0m     \u001b[39mreturn\u001b[39;00m original_result\n",
      "File \u001b[0;32m/opt/conda/envs/ml-env/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/opt/conda/envs/ml-env/lib/python3.10/site-packages/keras/src/saving/saving_api.py:142\u001b[0m, in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, save_format, **kwargs)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m    141\u001b[0m     \u001b[39mif\u001b[39;00m kwargs:\n\u001b[0;32m--> 142\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    143\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mThe following argument(s) are not supported \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    144\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mwith the native Keras format: \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlist\u001b[39m(kwargs\u001b[39m.\u001b[39mkeys())\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    145\u001b[0m         )\n\u001b[1;32m    146\u001b[0m     saving_lib\u001b[39m.\u001b[39msave_model(model, filepath)\n\u001b[1;32m    147\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    148\u001b[0m     \u001b[39m# Legacy case\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: The following argument(s) are not supported with the native Keras format: ['options']"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    mlflow.tensorflow.autolog()\n",
    "\n",
    "    # train the model for a certain number of epochs\n",
    "    model.fit(x_train, y_train,\n",
    "            batch_size=batch_size,\n",
    "            epochs=epochs,\n",
    "            validation_split= 0.2,\n",
    "            shuffle=True,\n",
    "            callbacks=[checkpoint_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'keras_cifar10_trained_model.h5' already exists. Creating a new version of this model...\n",
      "2023/08/14 12:01:57 INFO mlflow.tracking._model_registry.client: Waiting up to 300 seconds for model version to finish creation. Model name: keras_cifar10_trained_model.h5, version 7\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model trained in run 06b635ad-7512-4504-9d50-e47ce22b8339 of experiment cifar10_cnn_local registered under name keras_cifar10_trained_model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created version '7' of model 'keras_cifar10_trained_model.h5'.\n"
     ]
    }
   ],
   "source": [
    "# register model trained in last run\n",
    "runs = mlflow.search_runs(experiment_names=[experiment_name], output_format='list')\n",
    "run_id = runs[0].info.run_id\n",
    "artifact_path = 'model'\n",
    "model_version = mlflow.register_model(f\"runs:/{run_id}/{artifact_path}\", model_name)\n",
    "print(f\"model trained in run {run_id} of experiment {experiment_name} registered under name {model_version.name}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f2575392019334285e0602a4035eec46b9260ee4c95297ea34ade6e3c8b8fcaf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
